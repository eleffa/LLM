{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "6uqvj0qG4mrR",
    "outputId": "fb8bf759-7351-4649-82c1-57f0e2c47d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m61.4/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.9\n",
      "    Uninstalling openai-1.59.9:\n",
      "      Successfully uninstalled openai-1.59.9\n",
      "Successfully installed openai-0.28.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "cb6e05ea6a624232a8a41db68f3d31f3",
       "pip_warning": {
        "packages": [
         "openai"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfTcWhPZ4KiN",
    "outputId": "c16fbf92-630a-4876-b161-72dbc715e5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse du LLM : I'm sorry, but I don't have enough information to answer your question. Could you please provide more context or specify who or what \"Huhu\" is so I can assist you better?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Remplacez 'votre_cle_api' par votre clé API OpenAI\n",
    "openai.api_key = \"Put your OPENAI KEY HERE\"\n",
    "\n",
    "def simple_llm_call(prompt):\n",
    "    try:\n",
    "        # Effectuer un appel à l'API OpenAI avec le modèle GPT-3.5\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150,  # Limite de tokens pour la réponse\n",
    "            temperature=0.7, # Contrôle la créativité (0.0 à 1.0)\n",
    "        )\n",
    "\n",
    "        # Récupérer et retourner la réponse du modèle\n",
    "        return response.choices[0].message['content'].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors de l'appel à l'API : {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_tPiaH55DH4",
    "outputId": "79e18195-476e-4429-9257-132f490710be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse du LLM : La théorie de l'évolution est une explication scientifique qui explique comment les espèces vivantes changent et se transforment au fil du temps. Selon cette théorie, les êtres vivants ont évolué à partir d'ancêtres communs et se sont adaptés à leur environnement au fil des générations.\n",
      "\n",
      "L'évolution est principalement due à la sélection naturelle, un processus par lequel les individus les mieux adaptés à leur environnement ont de meilleures chances de survie et de reproduction, transmettant ainsi leurs caractéristiques à leur descendance.\n",
      "\n",
      "Au fil du temps, ces petits changements s'accumulent et conduisent à de\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "prompt = \"Explique-moi la théorie de l'évolution en termes simples.\"\n",
    "response = simple_llm_call(prompt)\n",
    "print(\"Réponse du LLM :\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKnTbqsf5CTg",
    "outputId": "1761a623-ce44-433d-e487-bfe448949c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse du LLM : I'm sorry, but I do not have information on an individual named Huhu. If you provide more context or details, I may be able to assist you further.\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "prompt = \"how many awards did Huhu won ?\"\n",
    "response = simple_llm_call(prompt)\n",
    "print(\"Réponse du LLM :\", response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
